{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '../'\n",
    "DRIVE_PATH = 'Colab/ToxicityClassification'\n",
    "\n",
    "# When on Colab, use Google Drive as the root path to persist and load data\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT_PATH = os.path.join('/content/drive/My Drive/', DRIVE_PATH)\n",
    "    os.makedirs(ROOT_PATH, exist_ok=True)\n",
    "    os.chdir(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the parent directory of the current script as a package root,\n",
    "# so that we can import modules from the parent directory\n",
    "sys.path.append(os.path.abspath(os.path.join(ROOT_PATH, 'src')))\n",
    "\n",
    "from toxicity.training import train_epochs, model_metrics\n",
    "from toxicity.embeddings.training import trainer, validate\n",
    "from toxicity.embeddings.model import EmbeddingModel, EmbeddingDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Target device for running the model\n",
    "PYTORCH_DEVICE = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# Random Seed\n",
    "RANDOM_SEED = 777\n",
    "\n",
    "# Training & Validation configs\n",
    "TRAIN_RATIO = 0.8\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "TEST_BATCH_SIZE = 16\n",
    "EPOCHS = 6\n",
    "LEARNING_RATE = 1e-05\n",
    "POS_WEIGHT = 1.663\n",
    "\n",
    "\n",
    "EMBEDDING_FILE = os.path.join(ROOT_PATH, 'cbow_s100.txt')\n",
    "EMBEDDING_NAME = 'cbow_s100'\n",
    "MAX_LEN = 128\n",
    "\n",
    "print(f'Using device: {PYTORCH_DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reseed(seed: int = RANDOM_SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "reseed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dataset</th><th>id</th><th>text</th><th>off_strict</th><th>off_relaxed</th><th>base_clean</th><th>base_clean_lower</th><th>tokenized</th><th>lemmatized</th><th>no_accents</th><th>lemma_no_accents</th><th>no_stop_words</th><th>lemma_no_stop_words</th><th>no_stop_words_no_accents</th><th>lemma_no_stop_words_no_accents</th></tr><tr><td>str</td><td>str</td><td>str</td><td>array[i32, 1]</td><td>array[i32, 1]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;17643984771725418028&quot;</td><td>&quot;caralho q vergonha kkkkk&quot;</td><td>[1]</td><td>[0]</td><td>&quot;caralho q vergonha kkkkk&quot;</td><td>&quot;caralho q vergonha kkkkk&quot;</td><td>[&quot;caralho&quot;, &quot;q&quot;, … &quot;kkkkk&quot;]</td><td>[&quot;caralho&quot;, &quot;q&quot;, … &quot;kkkkk&quot;]</td><td>[&quot;caralho&quot;, &quot;q&quot;, … &quot;kkkkk&quot;]</td><td>[&quot;caralho&quot;, &quot;q&quot;, … &quot;kkkkk&quot;]</td><td>[&quot;caralho&quot;, &quot;q&quot;, … &quot;kkkkk&quot;]</td><td>[&quot;caralho&quot;, &quot;q&quot;, … &quot;kkkkk&quot;]</td><td>[&quot;caralho&quot;, &quot;q&quot;, … &quot;kkkkk&quot;]</td><td>[&quot;caralho&quot;, &quot;q&quot;, … &quot;kkkkk&quot;]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;3886050625220892585&quot;</td><td>&quot;foda-se, vou encher o cu de po…</td><td>[1]</td><td>[0]</td><td>&quot;foda se vou encher o cu de por…</td><td>&quot;foda se vou encher o cu de por…</td><td>[&quot;foda&quot;, &quot;se&quot;, … &quot;lol&quot;]</td><td>[&quot;foda&quot;, &quot;se&quot;, … &quot;lol&quot;]</td><td>[&quot;foda&quot;, &quot;se&quot;, … &quot;lol&quot;]</td><td>[&quot;foda&quot;, &quot;se&quot;, … &quot;lol&quot;]</td><td>[&quot;foda&quot;, &quot;vou&quot;, … &quot;lol&quot;]</td><td>[&quot;foda&quot;, &quot;ir&quot;, … &quot;lol&quot;]</td><td>[&quot;foda&quot;, &quot;vou&quot;, … &quot;lol&quot;]</td><td>[&quot;foda&quot;, &quot;ir&quot;, … &quot;lol&quot;]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;14936095030342170465&quot;</td><td>&quot;USER USER USER Vc só pensa no …</td><td>[1]</td><td>[1]</td><td>&quot;USER USER USER Vc só pensa no …</td><td>&quot;user user user vc só pensa no …</td><td>[&quot;user&quot;, &quot;user&quot;, … &quot;esperta&quot;]</td><td>[&quot;user&quot;, &quot;user&quot;, … &quot;esperto&quot;]</td><td>[&quot;user&quot;, &quot;user&quot;, … &quot;esperta&quot;]</td><td>[&quot;user&quot;, &quot;user&quot;, … &quot;esperto&quot;]</td><td>[&quot;user&quot;, &quot;user&quot;, … &quot;esperta&quot;]</td><td>[&quot;user&quot;, &quot;user&quot;, … &quot;esperto&quot;]</td><td>[&quot;user&quot;, &quot;user&quot;, … &quot;esperta&quot;]</td><td>[&quot;user&quot;, &quot;user&quot;, … &quot;esperto&quot;]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;18279259074216789411&quot;</td><td>&quot;família&quot;</td><td>[0]</td><td>[0]</td><td>&quot;família&quot;</td><td>&quot;família&quot;</td><td>[&quot;família&quot;]</td><td>[&quot;família&quot;]</td><td>[&quot;familia&quot;]</td><td>[&quot;familia&quot;]</td><td>[&quot;família&quot;]</td><td>[&quot;família&quot;]</td><td>[&quot;familia&quot;]</td><td>[&quot;familia&quot;]</td></tr><tr><td>&quot;OLID-Br&quot;</td><td>&quot;7f36b160e8624968a32e82b1c6750f…</td><td>&quot;RT USER: vey a juliette veio c…</td><td>[0]</td><td>[0]</td><td>&quot;RT USER vey a juliette veio co…</td><td>&quot;rt user vey a juliette veio co…</td><td>[&quot;rt&quot;, &quot;user&quot;, … &quot;t&quot;]</td><td>[&quot;rt&quot;, &quot;user&quot;, … &quot;t&quot;]</td><td>[&quot;rt&quot;, &quot;user&quot;, … &quot;t&quot;]</td><td>[&quot;rt&quot;, &quot;user&quot;, … &quot;t&quot;]</td><td>[&quot;rt&quot;, &quot;user&quot;, … &quot;t&quot;]</td><td>[&quot;rt&quot;, &quot;user&quot;, … &quot;t&quot;]</td><td>[&quot;rt&quot;, &quot;user&quot;, … &quot;t&quot;]</td><td>[&quot;rt&quot;, &quot;user&quot;, … &quot;t&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 15)\n",
       "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ dataset ┆ id         ┆ text      ┆ off_stric ┆ … ┆ no_stop_w ┆ lemma_no_ ┆ no_stop_w ┆ lemma_no_ │\n",
       "│ ---     ┆ ---        ┆ ---       ┆ t         ┆   ┆ ords      ┆ stop_word ┆ ords_no_a ┆ stop_word │\n",
       "│ str     ┆ str        ┆ str       ┆ ---       ┆   ┆ ---       ┆ s         ┆ ccents    ┆ s_no_acce │\n",
       "│         ┆            ┆           ┆ array[i32 ┆   ┆ list[str] ┆ ---       ┆ ---       ┆ nts       │\n",
       "│         ┆            ┆           ┆ , 1]      ┆   ┆           ┆ list[str] ┆ list[str] ┆ ---       │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆           ┆ list[str] │\n",
       "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ ToLD-Br ┆ 1764398477 ┆ caralho q ┆ [1]       ┆ … ┆ [\"caralho ┆ [\"caralho ┆ [\"caralho ┆ [\"caralho │\n",
       "│         ┆ 1725418028 ┆ vergonha  ┆           ┆   ┆ \", \"q\", … ┆ \", \"q\", … ┆ \", \"q\", … ┆ \", \"q\", … │\n",
       "│         ┆            ┆ kkkkk     ┆           ┆   ┆ \"kkkkk\"]  ┆ \"kkkkk\"]  ┆ \"kkkkk\"]  ┆ \"kkkkk\"]  │\n",
       "│ ToLD-Br ┆ 3886050625 ┆ foda-se,  ┆ [1]       ┆ … ┆ [\"foda\",  ┆ [\"foda\",  ┆ [\"foda\",  ┆ [\"foda\",  │\n",
       "│         ┆ 220892585  ┆ vou       ┆           ┆   ┆ \"vou\", …  ┆ \"ir\", …   ┆ \"vou\", …  ┆ \"ir\", …   │\n",
       "│         ┆            ┆ encher o  ┆           ┆   ┆ \"lol\"]    ┆ \"lol\"]    ┆ \"lol\"]    ┆ \"lol\"]    │\n",
       "│         ┆            ┆ cu de po… ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ ToLD-Br ┆ 1493609503 ┆ USER USER ┆ [1]       ┆ … ┆ [\"user\",  ┆ [\"user\",  ┆ [\"user\",  ┆ [\"user\",  │\n",
       "│         ┆ 0342170465 ┆ USER Vc   ┆           ┆   ┆ \"user\", … ┆ \"user\", … ┆ \"user\", … ┆ \"user\", … │\n",
       "│         ┆            ┆ só pensa  ┆           ┆   ┆ \"esperta\" ┆ \"esperto\" ┆ \"esperta\" ┆ \"esperto\" │\n",
       "│         ┆            ┆ no …      ┆           ┆   ┆ ]         ┆ ]         ┆ ]         ┆ ]         │\n",
       "│ ToLD-Br ┆ 1827925907 ┆ família   ┆ [0]       ┆ … ┆ [\"família ┆ [\"família ┆ [\"familia ┆ [\"familia │\n",
       "│         ┆ 4216789411 ┆           ┆           ┆   ┆ \"]        ┆ \"]        ┆ \"]        ┆ \"]        │\n",
       "│ OLID-Br ┆ 7f36b160e8 ┆ RT USER:  ┆ [0]       ┆ … ┆ [\"rt\",    ┆ [\"rt\",    ┆ [\"rt\",    ┆ [\"rt\",    │\n",
       "│         ┆ 624968a32e ┆ vey a     ┆           ┆   ┆ \"user\", … ┆ \"user\", … ┆ \"user\", … ┆ \"user\", … │\n",
       "│         ┆ 82b1c6750f ┆ juliette  ┆           ┆   ┆ \"t\"]      ┆ \"t\"]      ┆ \"t\"]      ┆ \"t\"]      │\n",
       "│         ┆ …          ┆ veio c…   ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_parquet(os.path.join(ROOT_PATH, 'data', 'joint', 'pre_processed_data.parquet.zstd'))\n",
    "df = df.with_columns(\n",
    "    df['off_relaxed'].cast(pl.Int32).cast(pl.List(pl.Int32)).cast(pl.Array(pl.Int32, 1)),\n",
    "    df['off_strict'].cast(pl.Int32).cast(pl.List(pl.Int32)).cast(pl.Array(pl.Int32, 1)),\n",
    ")\n",
    "df.sample(5, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Length: 100\n",
      "Embedding Vocab Size: 929606; Expected: 929606\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_PATH = os.path.join(ROOT_PATH, 'models', f'embeddings-{EMBEDDING_NAME}')\n",
    "os.makedirs(EMBEDDING_PATH, exist_ok=True)\n",
    "\n",
    "emb_dim = None\n",
    "token_count = None\n",
    "embeddings = {}\n",
    "\n",
    "if not os.path.exists(f'{EMBEDDING_PATH}/embeddings.parquet.zstd'):\n",
    "    with open(EMBEDDING_FILE, 'r') as f:\n",
    "        fl = f.readline()\n",
    "        token_count, emb_dim = map(int, fl.split(' '))\n",
    "\n",
    "        while line := f.readline():\n",
    "            emb = line.split(' ')\n",
    "\n",
    "            token = emb[0]\n",
    "            values = [float(v) for v in emb[1:]]\n",
    "\n",
    "            if emb_dim is None:\n",
    "                emb_dim = len(values)\n",
    "            elif emb_dim != len(values):\n",
    "                raise ValueError('Inconsistent embedding length')\n",
    "\n",
    "            embeddings[token] = values\n",
    "    \n",
    "    print(f'Embedding Length: {emb_dim}')\n",
    "    print(f'Embedding Vocab Size: {len(embeddings)}; Expected: {token_count}')\n",
    "    embedding_df = pl.DataFrame({\n",
    "        'token': list(embeddings.keys()),\n",
    "        'embedding': list(embeddings.values())\n",
    "    })\n",
    "    embedding_df.write_parquet(f'{EMBEDDING_PATH}/embeddings.parquet.zstd', compression=\"zstd\", compression_level=9)\n",
    "else:\n",
    "    embedding_df = pl.read_parquet(f'{EMBEDDING_PATH}/embeddings.parquet.zstd')\n",
    "    # TODO: optimize this below\n",
    "    embeddings = {row['token']: row['embedding'] for row in embedding_df.to_dicts()}\n",
    "    emb_dim = len(embeddings[next(iter(embeddings))])\n",
    "    token_count = len(embeddings)\n",
    "    print(f'Embedding Length: {emb_dim}')\n",
    "    print(f'Embedding Vocab Size: {len(embeddings)}; Expected: {token_count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Model\n",
    "\n",
    "### Loss and Optimizer\n",
    "\n",
    "Using a Binary Cross Entropy loss as it shows good results for binary classification tasks. We are also applying differente weights to the positive and negative classes to account for the class imbalance.\n",
    "\n",
    "Adam optimizer is also used as it is a good general optimizer for training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbeddingModel(emb_dim, MAX_LEN)\n",
    "model.to(PYTORCH_DEVICE)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([POS_WEIGHT], device=PYTORCH_DEVICE))\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, train_size=TRAIN_RATIO, random_state=RANDOM_SEED)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    EmbeddingDataset(train_df, 'lemma_no_stop_words', 'off_relaxed', embeddings=embeddings, emb_dim=emb_dim, seq_len=MAX_LEN), \n",
    "    shuffle=True, num_workers=0, batch_size=TRAIN_BATCH_SIZE,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    EmbeddingDataset(test_df, 'lemma_no_stop_words', 'off_relaxed', embeddings=embeddings, emb_dim=emb_dim, seq_len=MAX_LEN), \n",
    "    shuffle=False, num_workers=0, batch_size=TEST_BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_result():\n",
    "    # Validate the results\n",
    "    raw_results, raw_targets = validate(model, test_loader, PYTORCH_DEVICE)\n",
    "    raw_results = np.array(raw_results)\n",
    "    raw_targets = np.array(raw_targets)\n",
    "\n",
    "    # Apply a fixed threshold to the results\n",
    "    FIXED_THRESHOLD = 0.5\n",
    "    fixed_results = raw_results > FIXED_THRESHOLD\n",
    "    fixed_targets = raw_targets > FIXED_THRESHOLD\n",
    "\n",
    "    # Compute metrics\n",
    "    print(f'Weighted F2: {model_metrics(fixed_targets, fixed_results)[\"weighted_f2\"]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135714dba95c447b8264800b33a67cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2369709bbe4451aa3c0a3f2edda494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F2: 0.590787\n",
      "Finished training epoch 1/10; Average Loss: 0.8467\n",
      "Running training epoch 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b6e35e8a2b4ca1a67b10365c92ae1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd15c3554ac4464af22fb0675bfcbeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F2: 0.674804\n",
      "Finished training epoch 2/10; Average Loss: 0.7655\n",
      "Running training epoch 3/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0c9e999dde4714a0aa3ce4005a13c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91f97f9df48416db79d96ef8942a335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F2: 0.691178\n",
      "Finished training epoch 3/10; Average Loss: 0.7180\n",
      "Running training epoch 4/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42dd2880f7b04344aebfc2604462537f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53530a3b0d6f42538c063ba2fde5257a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F2: 0.675966\n",
      "Finished training epoch 4/10; Average Loss: 0.6919\n",
      "Running training epoch 5/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa5e54cae6e4c79a6d13967feeeaf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0951cb1307452ca65be3679a90f405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F2: 0.689189\n",
      "Finished training epoch 5/10; Average Loss: 0.6701\n",
      "Running training epoch 6/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b896ba793e6448198abf850cc773527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6b67b4e9f8461dac249ec9533cd397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F2: 0.692351\n",
      "Finished training epoch 6/10; Average Loss: 0.6483\n",
      "Running training epoch 7/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e3a8b09dd6485b84d0ecbaba2cb3bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b910cb1e95a44cc887c988d864d4eb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F2: 0.679430\n",
      "Finished training epoch 7/10; Average Loss: 0.6264\n",
      "Running training epoch 8/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6635744ef4024957b7cbd4d58592b7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d70e68424448ba954d1360c4e6fd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F2: 0.688136\n",
      "Finished training epoch 8/10; Average Loss: 0.6017\n",
      "Running training epoch 9/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad282227f894452817869bb9d91a9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce650945f1ae40448de80c8d18eb37cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F2: 0.684593\n",
      "Finished training epoch 9/10; Average Loss: 0.5753\n",
      "Running training epoch 10/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8343712dccf74c82970ad55e280ff4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a908e3463a754042a5a0ef5cf71fe3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F2: 0.689354\n",
      "Finished training epoch 10/10; Average Loss: 0.5476\n"
     ]
    }
   ],
   "source": [
    "TIMESTAMP = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "MODEL_PATH = os.path.join(ROOT_PATH, 'models', f'embeddings-{EMBEDDING_NAME}', TIMESTAMP)\n",
    "CHECKPOINT_PATH = os.path.join(ROOT_PATH, 'checkpoints', f'embeddings-{EMBEDDING_NAME}', TIMESTAMP)\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "def epoch_callback(epoch, avg_loss):\n",
    "    print('Validation Results:')\n",
    "    validate_result()\n",
    "\n",
    "train_epochs(\n",
    "    trainer, EPOCHS, model, train_loader, loss_fn, optimizer, PYTORCH_DEVICE,\n",
    "    checkpoint_path=CHECKPOINT_PATH, epoch_callback=epoch_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'{MODEL_PATH}/model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
